# -*- coding: utf-8 -*-
"""Spark_Practica7.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1S9vTYzh8YBrJdEalcpCYWZALLplZB1l9
"""

!apt-get install openjdk-8-jdk
import os
import sys
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"
!pip install pyspark
import pandas as pd 
from tabulate import tabulate
from pyspark import SparkContext
import json
from datetime import date


from google.colab import drive
drive.mount('/content/drive') # Google Drive

#Esta función te indica si la fecha es entre semana (semana) o es fin de semana
#(finde) y el intervalo horario asignado por la práctica.

def fecha_hora(string):
  año = int(string[0:4])
  mes = int(string[5:7])
  dia = int(string[8:10])
  hora = int(string[11:13])
  dia_semana = date(año,mes,dia).weekday() #Obtención del dia de la semana
  es_o_fs = "semana"
  tramo = 1
  if dia_semana > 4: 
    es_o_fs = "finde"
  if hora >= 10 and hora < 13:
    tramo = 2
  elif hora >= 13 and hora < 16:
    tramo = 3
  elif hora >= 16 and hora < 21:
    tramo = 4
  elif hora >= 21 and hora < 23:
    tramo = 5
  elif hora >= 23 or (hora >= 00 and hora < 6):
    tramo = 6
  return (es_o_fs, tramo)

#Esta función te indica los puntos correspondientes dependiendo de la edad 
#del usuario. Las puntuaciones vienen establecidas en la memoria.

def edad(n):
  result = 1 #Corresponde con la edad del rango 4 y 5 (de 41 años en adelante)
  if n == 1:
     result = 4
  elif n == 2:
    result = 5
  elif n == 3:
    result = 3
  return result
 

#Función que te devuelve los puntos correpondientes dependiendo del tipo de 
#usuario. Las puntuaciones vienen establecidas en la memoria.

def tipo(typ):
  result = 1
  if typ == 2:
    result = 3
  return result



#Devuelve la puntuación correpondiente atendiendo al dia de la semana (si es 
#entre semana o fin de semana) y al tramo horario en el que se realiza el viaje.

#En este caso se trata de un usuario que ha realizado un viaje en un día.

def viaje1(es_o_fs,tramo):
  result = 1
  if es_o_fs == 'semana':
    if tramo == 1:
      result = 3
    elif tramo == 2:
      result = 2.5
    elif tramo == 3:
      result = 1.5
    elif tramo == 4 or tramo == 5:
      result = 3
    elif tramo == 6:
      result = 2
  else:
    if tramo == 3:
      result = 2
    elif tramo == 4:
      result == 3
    elif tramo == 5 or tramo == 6:
      result == 4
  return result



#Misma idea que la anterior función pero con dos viajes. Todas las puntuaciones 
#vienen establecidas en la practica

M_ES =[[3,2.5,1.5,3,3,2],[2.5,2,1.5,2.5,2.5,3],[1.5,1.5,1,2,2.5,3],[3,2.5,2,2,2.5,3],[3,2.5,2.5,2.5,2.5,4],[2,3,3,3,4,4]] #entre semana
M_FS = [[1,1,2,3,4,4],[1,1,2.5,3.5,3.5,4],[2,2.5,2,3.5,3.5,4],[3,3.5,3.5,3.5,4,4.5],[4,3.5,3.5,4,4,5],[4,4,4,4.5,5,5]] #fin de semana 

def viajes2(es_o_fs,a,b):
  result = 0
  if es_o_fs == 'semana':
    result = M_ES[a-1][b-1]
  elif es_o_fs == 'finde':
    result = M_FS[a-1][b-1]
  return result

#El mapper 1 extrae de la rdd la información correspondiente a edad, tipo, origen
#destino y fecha. Devuelve la información del pasajero y la información de su 
#viaje, utilizando las funciones anteriores


def mapper_1(line): 
  data = json.loads(line)
  usuario = data['user_day_code']
  edad = str(data['ageRange'])
  tipo = str(data['user_type'])
  origen = data['idunplug_station']
  destino = data['idplug_station']
  fecha = data['unplug_hourTime']
  fecha_y_hora = fecha_hora(fecha)
  pasajero = usuario + " " + edad + " " + tipo 
  viaje = (fecha_y_hora, origen, destino)
  return (pasajero, viaje)

#Construimos la primera rdd y utilizamos groupByKey para agruparlos por usuarios,
#dandonos todos los viajes que hace cada pasajero en un dia"""

#rrd_1 = (informacion pasajero, viajes que ha realizado)


#Transformamos las lineas de rdd_1 para convertirlas en diccionarios con su 
#clave y valor propio

def mapper_2(line): 
  pasajero = line[0]
  lista_pasajeros = pasajero.split() #Transformamos en lista
  lista_viajes = []
  for elementos in line[1]:
    lista_viajes.append(elementos)
  dicc = dict(id=lista_pasajeros[0],edad=int(lista_pasajeros[1]),tipo=int(lista_pasajeros[2]),viajes=lista_viajes) 
  return dicc

#rdd_2 = {id: ... , edad: .... , tipo: ...., viajes: [...,....,....]}




#Tomamos las lineas de rdd_2 para convertirlas en diccionarios que nos digan 
#los puntos por usuario y las estaciones que ha utilizado

def mapper_3(line):
  age = line['edad']
  typ = line['tipo']
  user = line['id']
  viajes = line['viajes'] # [(("semana",3), 2 , 127), (("finde",5), 3, 29)), ...]
  if edad == 0: #No hay información por edad
    parametro_edad = 0 #No añadimos el paramatro de la edad para hacer la media
    puntos_edad = 0 
  else:
    parametro_edad = 1
    puntos_edad = edad(age) #Averiguamos los puntos correspondientes a la edad
    
  if typ == 0: #No hay información del tipo
    parametro_tipo = 0 #No añadimos el parametro tipo para la media
    puntos_tipo = 0
    
  else:
    parametro_tipo = 1
    puntos_tipo = tipo(typ)
    

  parametro_viajes = 1 
  num_viajes = len(viajes) #Numero de viajes que hace el usuario en un dia

  if num_viajes == 1:
    es_o_fs = viajes[0][0][0]
    horario = viajes[0][0][1]
    puntos_viajes = viaje1(es_o_fs,horario) #Asignamos los puntos por 1 viaje

  elif num_viajes == 2:
    es_o_fs = viajes[0][0][0]
    horario1 = viajes[0][0][1]
    horario2 = viajes[1][0][1]
    puntos_viajes = viajes2(es_o_fs,horario1,horario2) #Asignamos los puntos por 2 viajes

  else:
    puntos_viajes = 2.5

  puntos_id = (puntos_viajes + puntos_tipo + puntos_edad)/(5*(parametro_viajes+parametro_edad+parametro_tipo))
  #Realizamos la media total de los puntos teniendo en cuenta el numero de parametros
  estaciones_id = []

  for trip in viajes:
    if (trip[1] in estaciones_id) == False:
      estaciones_id.append(trip[1])
    if (trip[2] in estaciones_id) == False:
      estaciones_id.append(trip[2])

  estaciones_id.sort() #Ordenamos la lista de estaciones

  dic = dict(id=user,puntos=puntos_id, estaciones=estaciones_id)
  return dic

#rdd_3 = {id: ..., puntos: .... , estaciones: [..,...,...]}



#Transformamos los diccionarios de la rdd_3 en diccionarios que nos indican 
#las puntuaciones que va teniendo cada estación. Cada linea de la rdd son las 
#estaciones por las que ha pasado el usuario en un dia y le atribuimos su puntuacion.

def mapper_4(line):
  points = line['puntos']
  estaciones = line['estaciones']
  lista_salida = []
  for i in estaciones:
    est = 'estacion'+str(i)
    valor = {'puntos': points, 'numero_personas':1}
    lista_salida.append((est,valor))
  return lista_salida

#rdd_4 = [(estacion19, {puntos: ... , numero personas: 1}), (estacion50, {puntos: ... , numero personas: 1}), ....]
#La rdd_4 tiene exactamente el mismo numero de lineas que la rdd_3 y cada linea 
#corresponde con las estaciones que ha tenido contacto el usuario.



#Definimos la función que nos ayudará a realizar la reducción. Simplemente devuelve
#la lista más larga de la rdd

def reducer(list_1,list_2):
  if len(list_1) > len(list_2):
    return list_1
  else:
    return list_2 

"""
lista_grande = rdd_4.reduce(reducer)

Se trata de un unico diccionario cuya longitud es el maximo numero de estaciones
que ha utilizado una persona en un dia.


Ahora creamos tantas rdds como longitud tenga lista grande. 
En la primera de ellas pondremos todos los primeros viajes de cada cliente.
En la segunda todos los segundos viajes y asi ....
En el caso de que un cliente no haya realizado 2,3,4,... viajes se pondra una 
tupla vacia que luego filtraremos.
Si n = len(lista_grande), tendremos n rdds con n elementos cada una (algunos por
supuesto serán tuplas vacias)


print("Iniciando separación de RDD's...")
print("Uniendo las RDD's por estación...")
"""
#Toma el elemento n-ésimo de cada línea. En caso de que no lo tenga devuelve
#una tupla vacia.

def mapper_5(n, line):                      
  longitud = len(line)
  if n < len(line):
    return line[n]
  else:
    tupla_vacia = ()
    return tupla_vacia

#Primero se mapean los primeros elementos que corresponden con los primeros viajes 
#de cada cliente (que siempre existen y por tanto no habrá tuplas vacias). Y luego 
#recorremos los demás elementos realizando una unión de todos creando una única 
#rdd con todos los elementos juntos.
"""
rdd_5 = rdd_4.map(lambda x: mapper_5(0, x)) #mapeamos los primeros elementos
i = 1
while i < len(lista_grande):
  rdd_5 = rdd_5.union(rdd_4.map(lambda x: mapper_5(i, x))) 
  i = i + 1
"""


#Filtramos las tuplas vacias para la rdd_6 y las agrupamos por estaciones con groupByKey

#rdd_6 = rdd_5.filter(lambda x: x != ()).groupByKey() 

#rdd_6 = (estacion19, [{puntos: ...., numero personas: 1}, {puntos: ...., numero personas: 1}, .... , ...])



#Para cada estación cogemos los puntos que tengan y hacemos una media de los puntos entre 
#el total de los usos. Además apuntamos cuantos usos son de riesgo bajo y cuales son de 
#riesgo alto.


def mapper_6(line): 
  est = line[0]
  lista = line[1]
  final = {'estacion': int(est[8:]), 'media': 0, 'usos': 0, 'riesgo_bajo': 0, 'riesgo_alto': 0}
  for elem in lista:
    final['media'] = final['media'] + elem['puntos'] #Numero total de puntos
    final['usos'] = final['usos'] + elem['numero_personas'] #Numero total usos
    if elem['puntos'] < 0.5:
      final['riesgo_bajo'] = final['riesgo_bajo'] + elem['numero_personas'] #Numero total riesgo bajo
    elif elem['puntos'] > 0.5:
      final['riesgo_alto'] = final['riesgo_alto'] + elem['numero_personas'] #Numero total riesgo alto
  final['media'] = final['media']/final['usos']
  return final

#rdd_7 = {estacion: ..., media: ...., usos: ..., riesgo_bajo: ...., riesgo_alto: ....}



def main(sc, archivos):
  rdd = sc.textFile(archivos[0])
  i = 1
  if i < len(archivos):
    rdd = rdd.union(sc.textFile(archivos[i]))
    i = i + 1
  rdd_1 = rdd.map(mapper_1).groupByKey() 
  print("----------------------")
  print("Cargado RRD_1")

  rdd_2 = rdd_1.map(mapper_2)
  print("-------------------") 
  print("Cargado RRD_2")

  rdd_3 = rdd_2.map(mapper_3)
  print("----------------")
  print("Cargado RRD_3")

  rdd_4 = rdd_3.map(mapper_4)
  print("------------------")
  print("Cargado RRD_4")

  
  lista_grande = rdd_4.reduce(reducer)
  print("Uniendo las RDD's ...")
  rdd_5 = rdd_4.map(lambda x: mapper_5(0, x))
  i = 1
  while i < len(lista_grande):
    rdd_5 = rdd_5.union(rdd_4.map(lambda x: mapper_5(i, x)))
    i = i + 1
  print("Cargado RRD_5")

  rdd_6 = rdd_5.filter(lambda x: x != ()).groupByKey()
  print("------------------")
  print("Cargado RRD_6")

  rdd_7 = rdd_6.map(mapper_6)
  print("------------------")
  print("Cargado RRD_7")
  print("Guardando RDD como lista_riesgo.json...")
  
  rdd_7 = rdd_7.coalesce(1, shuffle=True) #unimos el RDD en una sola partición

  # Hacemos un map de todos los elementos del RDD a string
  rdd_7 = rdd_7.map(json.dumps)

  # Hacemos la reducción a una gran string separada por líneas con todos los datos
  json_string = rdd_7.reduce(lambda x, y: x + "\n" + y)

  # Exportamos a todo a un unico archivo
  with open("lista_riesgo.json", "w") as f:
    f.write(json_string)

  print("Archivo creado completado")
  print("Resultados publicados en el archivo lista_riesgo.json")


if __name__ == "__main__":
  print("Bienvenido al  estudio de BICIMAD")
  print("Programado por Alfonso Montalvo Fernandez")
  print("Este programa analiza los archivos proporcionados por la comundidad de Madrid")
  print("de BICIMAD para dar unos resultados que nos digan las estaciones donde haya   ")
  print("mas riesgo de accidentes y asi poder actuar en consecuencia")
  print("--------------------------")
  print("Introduce la ruta de los archivos que quieras analizar")
  print("Escribe INICIAR para comenzar el analisis")
  i = 0
  j = 0
  archivos = []
  archivo = input()
  while j != 1:
    if archivo == "iniciar" or archivo == "INICIAR" or archivo[-5:] != ".json":
      print("No has introducido ningún archivo o tu archivo no es de la extension .json.")
      archivo = input()
    else:
      j = 1
      archivos.append(archivo)
  archivo = input()
  while i != 1:
    if archivo != "iniciar" and archivo != "INICIAR":
      if archivo[-5:] != ".json":
        print("Por favor, introduce archivos con extensión .json")
        archivo = input()
      else:
        archivos.append(archivo)
        archivo = input()
    else:
      i = 1
  sc = SparkContext()
  main(sc, archivos)
  sc.stop()

